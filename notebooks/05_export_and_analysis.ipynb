{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Data Export and Analysis\n",
        "\n",
        "This notebook exports processed data and provides analysis of the collected entities.\n",
        "\n",
        "## What this notebook covers:\n",
        "- CSV export of processed data\n",
        "- Cross-channel entity analysis\n",
        "- Summary statistics\n",
        "- Data visualization and insights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup\n",
        "import pandas as pd\n",
        "import sqlite3\n",
        "import json\n",
        "from pathlib import Path\n",
        "from collections import defaultdict\n",
        "\n",
        "print(\"Export and analysis setup complete\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load Data from Database\n",
        "db_path = Path(\"data/processed_messages.db\")\n",
        "\n",
        "if not db_path.exists():\n",
        "    print(\"Database not found! Please run notebook 04 first.\")\n",
        "    print(\"Creating sample data for demo...\")\n",
        "    \n",
        "    # Create sample data for demo\n",
        "    db_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    with sqlite3.connect(db_path) as conn:\n",
        "        cursor = conn.cursor()\n",
        "        cursor.execute(\"\"\"\n",
        "            CREATE TABLE IF NOT EXISTS processed_messages (\n",
        "                id INTEGER, channel TEXT, channel_title TEXT, original_text TEXT,\n",
        "                cleaned_text TEXT, date TEXT, views INTEGER, entities TEXT,\n",
        "                PRIMARY KEY (id, channel)\n",
        "            )\n",
        "        \"\"\")\n",
        "        \n",
        "        # Insert sample data\n",
        "        sample_data = [\n",
        "            (123, '@ShegerOnlineStore', 'Sheger Online Shopping', \n",
        "             'የሴቶች ቦርሳ ዋጋ 2500 ብር በአዲስ አበባ', \n",
        "             'የሴቶች ቦርሳ ዋጋ 2500 ብር በአዲስ አበባ',\n",
        "             '2024-01-01T10:00:00', 150, \n",
        "             '{\"prices\": [\"2500\"], \"locations\": [\"አዲስ አበባ\"], \"products\": [\"ቦርሳ\"]}'),\n",
        "            (124, '@ShegerOnlineStore', 'Sheger Online Shopping',\n",
        "             'ሞባይል ፎን 15000 ብር delivery ከነ ቦሌ',\n",
        "             'ሞባይል ፎን 15000 ብር delivery ከነ ቦሌ', \n",
        "             '2024-01-01T11:00:00', 200,\n",
        "             '{\"prices\": [\"15000\"], \"locations\": [\"ቦሌ\"], \"products\": [\"ሞባይል\", \"ፎን\"]}')\n",
        "        ]\n",
        "        \n",
        "        for data in sample_data:\n",
        "            cursor.execute(\"\"\"\n",
        "                INSERT OR REPLACE INTO processed_messages \n",
        "                VALUES (?, ?, ?, ?, ?, ?, ?, ?)\n",
        "            \"\"\", data)\n",
        "        conn.commit()\n",
        "\n",
        "# Load data from database\n",
        "with sqlite3.connect(db_path) as conn:\n",
        "    df = pd.read_sql_query(\"SELECT * FROM processed_messages\", conn)\n",
        "\n",
        "print(f\"Loaded {len(df)} processed messages from database\")\n",
        "print(f\"Channels: {df['channel'].unique().tolist()}\")\n",
        "\n",
        "# Parse entities JSON\n",
        "df['entities_parsed'] = df['entities'].apply(json.loads)\n",
        "\n",
        "print(\"\\nSample data:\")\n",
        "print(df[['channel', 'original_text', 'entities']].head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze Entities Across Channels\n",
        "print(\"Entity Analysis Across Channels:\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "# Collect all entities by type\n",
        "all_entities = defaultdict(list)\n",
        "channel_stats = {}\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    channel = row['channel']\n",
        "    entities = row['entities_parsed']\n",
        "    \n",
        "    if channel not in channel_stats:\n",
        "        channel_stats[channel] = {\n",
        "            'messages': 0,\n",
        "            'prices': set(),\n",
        "            'products': set(), \n",
        "            'locations': set()\n",
        "        }\n",
        "    \n",
        "    channel_stats[channel]['messages'] += 1\n",
        "    \n",
        "    for entity_type, entity_list in entities.items():\n",
        "        all_entities[entity_type].extend(entity_list)\n",
        "        channel_stats[channel][entity_type].update(entity_list)\n",
        "\n",
        "# Print channel statistics\n",
        "for channel, stats in channel_stats.items():\n",
        "    print(f\"\\n{channel}:\")\n",
        "    print(f\"  Messages: {stats['messages']}\")\n",
        "    print(f\"  Unique prices: {len(stats['prices'])} - {sorted(stats['prices'])}\")\n",
        "    print(f\"  Unique products: {len(stats['products'])} - {list(stats['products'])}\")\n",
        "    print(f\"  Unique locations: {len(stats['locations'])} - {list(stats['locations'])}\")\n",
        "\n",
        "# Overall statistics\n",
        "print(f\"\\nOverall Statistics:\")\n",
        "print(f\"  Total channels: {len(channel_stats)}\")\n",
        "print(f\"  Total messages: {len(df)}\")\n",
        "print(f\"  Unique prices: {len(set(all_entities['prices']))} - {sorted(set(all_entities['prices']))}\")\n",
        "print(f\"  Unique products: {len(set(all_entities['products']))} - {list(set(all_entities['products']))}\")\n",
        "print(f\"  Unique locations: {len(set(all_entities['locations']))} - {list(set(all_entities['locations']))}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export to CSV\n",
        "export_dir = Path(\"data/processed\")\n",
        "export_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Prepare data for CSV export\n",
        "csv_data = []\n",
        "for _, row in df.iterrows():\n",
        "    entities = row['entities_parsed']\n",
        "    csv_row = {\n",
        "        'message_id': row['id'],\n",
        "        'channel': row['channel'],\n",
        "        'channel_title': row['channel_title'],\n",
        "        'text': row['original_text'],\n",
        "        'cleaned_text': row['cleaned_text'],\n",
        "        'date': row['date'],\n",
        "        'views': row['views'],\n",
        "        'products': ', '.join(entities['products']),\n",
        "        'prices': ', '.join(entities['prices']),\n",
        "        'locations': ', '.join(entities['locations']),\n",
        "        'entities_json': row['entities']\n",
        "    }\n",
        "    csv_data.append(csv_row)\n",
        "\n",
        "# Create DataFrame and export\n",
        "export_df = pd.DataFrame(csv_data)\n",
        "csv_path = export_dir / \"processed_messages.csv\"\n",
        "export_df.to_csv(csv_path, index=False)\n",
        "\n",
        "print(f\"Exported data to: {csv_path}\")\n",
        "print(f\"CSV contains {len(export_df)} rows from {len(df['channel'].unique())} channels\")\n",
        "\n",
        "# Show preview\n",
        "print(f\"\\nCSV Preview:\")\n",
        "preview_cols = ['channel', 'text', 'products', 'prices', 'locations']\n",
        "print(export_df[preview_cols].to_string(max_colwidth=40, index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create Channel Summary Report\n",
        "summary_data = []\n",
        "for channel, stats in channel_stats.items():\n",
        "    summary_row = {\n",
        "        'channel': channel,\n",
        "        'channel_title': df[df['channel'] == channel]['channel_title'].iloc[0],\n",
        "        'message_count': stats['messages'],\n",
        "        'unique_prices': len(stats['prices']),\n",
        "        'unique_products': len(stats['products']),\n",
        "        'unique_locations': len(stats['locations']),\n",
        "        'prices': ', '.join(sorted(stats['prices'])),\n",
        "        'products': ', '.join(stats['products']),\n",
        "        'locations': ', '.join(stats['locations'])\n",
        "    }\n",
        "    summary_data.append(summary_row)\n",
        "\n",
        "summary_df = pd.DataFrame(summary_data)\n",
        "summary_path = export_dir / \"channel_summary.csv\"\n",
        "summary_df.to_csv(summary_path, index=False)\n",
        "\n",
        "print(f\"Exported channel summary to: {summary_path}\")\n",
        "print(f\"\\nChannel Summary:\")\n",
        "print(summary_df[['channel', 'message_count', 'unique_prices', 'unique_products', 'unique_locations']].to_string(index=False))\n",
        "\n",
        "print(f\"\\nTask 1 Complete!\")\n",
        "print(f\"Data files created:\")\n",
        "print(f\"  - Database: {db_path}\")\n",
        "print(f\"  - Messages CSV: {csv_path}\")\n",
        "print(f\"  - Summary CSV: {summary_path}\")\n",
        "print(f\"\\nReady for Task 2: CoNLL labeling and NER training!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
