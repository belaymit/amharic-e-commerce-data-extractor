{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Data Processing and Analysis\n",
        "\n",
        "This notebook processes scraped messages and extracts entities for analysis.\n",
        "\n",
        "## What this notebook covers:\n",
        "- Processing scraped messages with Amharic text processor\n",
        "- Entity extraction across multiple channels\n",
        "- Data storage in SQLite database\n",
        "- Cross-channel data analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup\n",
        "import sqlite3\n",
        "import json\n",
        "import regex\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Any\n",
        "\n",
        "# Initialize Amharic processor (copy from notebook 02)\n",
        "class AmharicProcessor:\n",
        "    \"\"\"Simplified Amharic text processor for e-commerce data.\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.price_patterns = [\n",
        "            regex.compile(r'(\\d+(?:,\\d{3})*(?:\\.\\d{2})?)\\s*(?:ብር|birr|ETB)', regex.IGNORECASE),\n",
        "            regex.compile(r'(?:ዋጋ|ዋጋው|በ)\\s*(\\d+(?:,\\d{3})*(?:\\.\\d{2})?)', regex.IGNORECASE),\n",
        "        ]\n",
        "        self.location_keywords = ['አዲስ አበባ', 'አዲስ ዓባባ', 'ቦሌ', 'ገርጂ', 'ንግሥት', 'ማርካቶ', 'ፒያሳ']\n",
        "        self.product_keywords = ['ቦርሳ', 'ሞባይል', 'ፎን', 'ልብስ', 'ሻምፖ', 'cream', 'lotion', 'bottle']\n",
        "    \n",
        "    def clean_text(self, text: str) -> str:\n",
        "        if not text:\n",
        "            return \"\"\n",
        "        return regex.sub(r'\\s+', ' ', text).strip()\n",
        "    \n",
        "    def extract_entities(self, text: str) -> Dict[str, List[str]]:\n",
        "        entities = {'prices': [], 'locations': [], 'products': []}\n",
        "        \n",
        "        if not text:\n",
        "            return entities\n",
        "        \n",
        "        # Extract prices\n",
        "        for price_pattern in self.price_patterns:\n",
        "            matches = price_pattern.findall(text)\n",
        "            entities['prices'].extend(matches)\n",
        "        \n",
        "        # Extract locations\n",
        "        for location in self.location_keywords:\n",
        "            if location in text:\n",
        "                entities['locations'].append(location)\n",
        "        \n",
        "        # Extract products\n",
        "        for keyword in self.product_keywords:\n",
        "            if keyword.lower() in text.lower():\n",
        "                entities['products'].append(keyword)\n",
        "        \n",
        "        # Remove duplicates\n",
        "        for key in entities:\n",
        "            entities[key] = list(set(entities[key]))\n",
        "        \n",
        "        return entities\n",
        "\n",
        "processor = AmharicProcessor()\n",
        "print(\"Data processing setup complete\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load Sample Scraped Data\n",
        "# Note: This assumes you've run notebook 03 and have scraped_messages\n",
        "# For demo purposes, we'll create sample data if none exists\n",
        "\n",
        "sample_scraped_messages = {\n",
        "    \"@ShegerOnlineStore\": [\n",
        "        {\n",
        "            'id': 123,\n",
        "            'channel': '@ShegerOnlineStore',\n",
        "            'channel_title': 'Sheger Online Shopping',\n",
        "            'text': 'የሴቶች ቦርሳ ዋጋ 2500 ብር በአዲስ አበባ',\n",
        "            'date': '2024-01-01T10:00:00',\n",
        "            'views': 150,\n",
        "            'has_media': False\n",
        "        },\n",
        "        {\n",
        "            'id': 124,\n",
        "            'channel': '@ShegerOnlineStore', \n",
        "            'channel_title': 'Sheger Online Shopping',\n",
        "            'text': 'ሞባይል ፎን 15000 ብር delivery ከነ ቦሌ',\n",
        "            'date': '2024-01-01T11:00:00',\n",
        "            'views': 200,\n",
        "            'has_media': True\n",
        "        }\n",
        "    ],\n",
        "    \"@ethio_commerce\": [\n",
        "        {\n",
        "            'id': 456,\n",
        "            'channel': '@ethio_commerce',\n",
        "            'channel_title': 'Ethio Commerce',\n",
        "            'text': 'Baby bottle በ 150 birr ገርጂ ላይ',\n",
        "            'date': '2024-01-01T12:00:00',\n",
        "            'views': 75,\n",
        "            'has_media': False\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Use actual scraped data if available (from previous notebook)\n",
        "try:\n",
        "    # This will work if you ran notebook 03 first\n",
        "    scraped_messages\n",
        "    print(\"Using scraped data from previous notebook\")\n",
        "except NameError:\n",
        "    # Use sample data for demo\n",
        "    scraped_messages = sample_scraped_messages\n",
        "    print(\"Using sample data for processing demo\")\n",
        "\n",
        "print(f\"Processing data from {len(scraped_messages)} channels\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Process Messages and Extract Entities\n",
        "processed_results = {}\n",
        "\n",
        "print(\"Processing messages for entity extraction:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "for channel, messages in scraped_messages.items():\n",
        "    print(f\"\\nProcessing {channel} ({len(messages)} messages):\")\n",
        "    channel_processed = []\n",
        "    \n",
        "    for i, message in enumerate(messages, 1):\n",
        "        if message['text']:\n",
        "            print(f\"\\n  {i}. Message {message['id']}:\")\n",
        "            print(f\"     Original: {message['text'][:70]}...\")\n",
        "            \n",
        "            # Clean text\n",
        "            cleaned_text = processor.clean_text(message['text'])\n",
        "            \n",
        "            # Extract entities\n",
        "            entities = processor.extract_entities(cleaned_text)\n",
        "            \n",
        "            processed_data = {\n",
        "                'message_id': message['id'],\n",
        "                'channel': channel,\n",
        "                'channel_title': message['channel_title'],\n",
        "                'original_text': message['text'],\n",
        "                'cleaned_text': cleaned_text,\n",
        "                'date': message['date'],\n",
        "                'views': message['views'],\n",
        "                'entities': entities\n",
        "            }\n",
        "            \n",
        "            channel_processed.append(processed_data)\n",
        "            \n",
        "            print(f\"     Products: {entities['products']}\")\n",
        "            print(f\"     Prices: {entities['prices']}\")\n",
        "            print(f\"     Locations: {entities['locations']}\")\n",
        "    \n",
        "    processed_results[channel] = channel_processed\n",
        "    print(f\"\\nProcessed {len(channel_processed)} messages from {channel}\")\n",
        "\n",
        "print(f\"\\nProcessing complete for {len(processed_results)} channels\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save to Database\n",
        "db_path = Path(\"data/processed_messages.db\")\n",
        "db_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Initialize database\n",
        "with sqlite3.connect(db_path) as conn:\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS processed_messages (\n",
        "            id INTEGER,\n",
        "            channel TEXT,\n",
        "            channel_title TEXT,\n",
        "            original_text TEXT,\n",
        "            cleaned_text TEXT,\n",
        "            date TEXT,\n",
        "            views INTEGER,\n",
        "            entities TEXT,\n",
        "            PRIMARY KEY (id, channel)\n",
        "        )\n",
        "    \"\"\")\n",
        "    conn.commit()\n",
        "\n",
        "# Save all processed data\n",
        "total_saved = 0\n",
        "for channel, messages in processed_results.items():\n",
        "    for msg in messages:\n",
        "        with sqlite3.connect(db_path) as conn:\n",
        "            cursor = conn.cursor()\n",
        "            cursor.execute(\"\"\"\n",
        "                INSERT OR REPLACE INTO processed_messages \n",
        "                (id, channel, channel_title, original_text, cleaned_text, date, views, entities)\n",
        "                VALUES (?, ?, ?, ?, ?, ?, ?, ?)\n",
        "            \"\"\", (\n",
        "                msg['message_id'], \n",
        "                msg['channel'], \n",
        "                msg['channel_title'],\n",
        "                msg['original_text'],\n",
        "                msg['cleaned_text'],\n",
        "                msg['date'], \n",
        "                msg['views'],\n",
        "                json.dumps(msg['entities'])\n",
        "            ))\n",
        "            conn.commit()\n",
        "            total_saved += 1\n",
        "\n",
        "print(f\"Saved {total_saved} processed messages to database: {db_path}\")\n",
        "\n",
        "# Verify data was saved\n",
        "with sqlite3.connect(db_path) as conn:\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"SELECT COUNT(*) FROM processed_messages\")\n",
        "    count = cursor.fetchone()[0]\n",
        "    print(f\"Database contains {count} processed messages\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
