{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Task 2: CoNLL Format Labeling for Amharic NER\n",
        "\n",
        "## üéØ Objective\n",
        "Create **CoNLL format labeled data** from Amharic e-commerce messages for Named Entity Recognition (NER) training.\n",
        "\n",
        "## üìã Requirements\n",
        "- Label **30-50 messages** in CoNLL format\n",
        "- Entity types: **Product**, **Location**, **Price**  \n",
        "- Save as plain text file for NER training\n",
        "\n",
        "## üè∑Ô∏è Entity Types\n",
        "- `B-PRODUCT`, `I-PRODUCT`: Product names\n",
        "- `B-LOC`, `I-LOC`: Location names\n",
        "- `B-PRICE`, `I-PRICE`: Price expressions\n",
        "- `O`: Outside any entity\n",
        "\n",
        "## üìä Expected Output\n",
        "```\n",
        "# Message 1: ·ã®·à¥·â∂·âΩ ·â¶·à≠·à≥ ·ãã·åã 2500 ·â•·à≠ ·â†·ä†·ã≤·àµ ·ä†·â†·â£\n",
        "·ã®·à¥·â∂·âΩ\tO\n",
        "·â¶·à≠·à≥\tB-PRODUCT\n",
        "·ãã·åã\tB-PRICE\n",
        "2500\tI-PRICE\n",
        "·â•·à≠\tI-PRICE\n",
        "·â†·ä†·ã≤·àµ\tO\n",
        "·ä†·ã≤·àµ\tB-LOC\n",
        "·ä†·â†·â£\tI-LOC\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Setup and Configuration\n",
        "import sys\n",
        "import sqlite3\n",
        "import json\n",
        "import re\n",
        "from pathlib import Path\n",
        "from collections import Counter, defaultdict\n",
        "from typing import List, Tuple, Dict, Any\n",
        "from datetime import datetime\n",
        "\n",
        "print(\"üè∑Ô∏è Task 2: CoNLL Format Labeling for Amharic NER\")\n",
        "print(\"=\" * 60)\n",
        "print(\"Setting up CoNLL labeling system...\")\n",
        "\n",
        "# Add project root to path\n",
        "project_root = Path.cwd().parent if 'notebook' in str(Path.cwd()) else Path.cwd()\n",
        "sys.path.insert(0, str(project_root))\n",
        "\n",
        "print(f\"‚úÖ Project root: {project_root}\")\n",
        "print(\"Ready to start CoNLL labeling!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. Load and Preview Data\n",
        "print(\"üìä Loading data for CoNLL labeling...\")\n",
        "\n",
        "# Try to load from existing databases\n",
        "data_sources = [\n",
        "    project_root / \"data/processed/amharic_ecommerce.db\",\n",
        "    project_root / \"data/historical_messages.db\", \n",
        "    project_root / \"data/demo.db\"\n",
        "]\n",
        "\n",
        "messages = []\n",
        "for db_path in data_sources:\n",
        "    if db_path.exists():\n",
        "        print(f\"üìÇ Found database: {db_path}\")\n",
        "        try:\n",
        "            conn = sqlite3.connect(db_path)\n",
        "            cursor = conn.cursor()\n",
        "            \n",
        "            # Check available tables\n",
        "            cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table'\")\n",
        "            tables = [row[0] for row in cursor.fetchall()]\n",
        "            print(f\"   Available tables: {tables}\")\n",
        "            \n",
        "            # Try to load messages from any available table\n",
        "            for table in ['processed_messages', 'historical_messages', 'messages']:\n",
        "                if table in tables:\n",
        "                    cursor.execute(f\"SELECT * FROM {table} LIMIT 50\")\n",
        "                    rows = cursor.fetchall()\n",
        "                    if rows:\n",
        "                        cursor.execute(f\"PRAGMA table_info({table})\")\n",
        "                        columns = [row[1] for row in cursor.fetchall()]\n",
        "                        messages = [dict(zip(columns, row)) for row in rows]\n",
        "                        print(f\"   ‚úÖ Loaded {len(messages)} messages from {table}\")\n",
        "                        break\n",
        "            \n",
        "            conn.close()\n",
        "            if messages:\n",
        "                break\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"   ‚ùå Error loading from {db_path}: {e}\")\n",
        "\n",
        "print(f\"\\nüìã Data Summary:\")\n",
        "print(f\"   Messages loaded: {len(messages)}\")\n",
        "if messages:\n",
        "    sample_msg = messages[0]\n",
        "    print(f\"   Sample fields: {list(sample_msg.keys())}\")\n",
        "    text_field = None\n",
        "    for field in ['text', 'original_text', 'message']:\n",
        "        if field in sample_msg:\n",
        "            text_field = field\n",
        "            break\n",
        "    \n",
        "    if text_field:\n",
        "        print(f\"   Text field: '{text_field}'\")\n",
        "        print(f\"   Sample text: {sample_msg[text_field][:100]}...\")\n",
        "    else:\n",
        "        print(\"   ‚ö†Ô∏è No text field found\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. Run CoNLL Labeling System\n",
        "print(\"üè∑Ô∏è Running CoNLL labeling process...\")\n",
        "\n",
        "# Run the labeling script\n",
        "import subprocess\n",
        "result = subprocess.run(['python3', 'task2_conll_labeling.py'], \n",
        "                       capture_output=True, text=True, cwd=project_root)\n",
        "\n",
        "print(\"STDOUT:\")\n",
        "print(result.stdout)\n",
        "\n",
        "if result.stderr:\n",
        "    print(\"STDERR:\")\n",
        "    print(result.stderr)\n",
        "\n",
        "print(f\"Return code: {result.returncode}\")\n",
        "\n",
        "# Check if files were created\n",
        "output_dir = project_root / \"data/conll_labeled\"\n",
        "conll_file = output_dir / \"amharic_ecommerce_conll.txt\"\n",
        "stats_file = output_dir / \"labeling_statistics.json\"\n",
        "\n",
        "print(f\"\\nüìÅ Output Files:\")\n",
        "print(f\"   CoNLL file exists: {conll_file.exists()}\")\n",
        "print(f\"   Stats file exists: {stats_file.exists()}\")\n",
        "\n",
        "if stats_file.exists():\n",
        "    with open(stats_file, 'r', encoding='utf-8') as f:\n",
        "        stats = json.load(f)\n",
        "    print(f\"\\nüìä Labeling Statistics:\")\n",
        "    print(f\"   Messages processed: {stats['total_messages_processed']}\")\n",
        "    print(f\"   Total tokens: {stats['total_tokens']:,}\")\n",
        "    print(f\"   Total entities: {stats['total_entities']}\")\n",
        "    print(f\"   Entity distribution: {stats['entity_counts']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4. Validate CoNLL Format\n",
        "print(\"üß™ Validating CoNLL format...\")\n",
        "\n",
        "# Run the validation script\n",
        "result = subprocess.run(['python3', 'test_conll_format.py'], \n",
        "                       capture_output=True, text=True, cwd=project_root)\n",
        "\n",
        "print(\"STDOUT:\")\n",
        "print(result.stdout)\n",
        "\n",
        "if result.stderr:\n",
        "    print(\"STDERR:\")\n",
        "    print(result.stderr)\n",
        "\n",
        "print(f\"Return code: {result.returncode}\")\n",
        "\n",
        "# Load validation report\n",
        "validation_file = output_dir / \"validation_report.json\"\n",
        "if validation_file.exists():\n",
        "    with open(validation_file, 'r', encoding='utf-8') as f:\n",
        "        validation_report = json.load(f)\n",
        "    \n",
        "    print(f\"\\n‚úÖ Validation Summary:\")\n",
        "    checks = validation_report['requirements_check']\n",
        "    print(f\"   Message count (30-50): {'‚úÖ' if checks['message_count_ok'] else '‚ùå'}\")\n",
        "    print(f\"   CoNLL format valid: {'‚úÖ' if checks['format_valid'] else '‚ùå'}\")\n",
        "    print(f\"   All entity types found: {'‚úÖ' if checks['all_entity_types_found'] else '‚ùå'}\")\n",
        "    \n",
        "    if all(checks.values()):\n",
        "        print(\"\\nüéâ Task 2 PASSED: Ready for NER training!\")\n",
        "    else:\n",
        "        print(\"\\n‚ö†Ô∏è Task 2 ISSUES: Some requirements need attention\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5. Preview CoNLL Output\n",
        "print(\"üëÄ Previewing CoNLL format output...\")\n",
        "\n",
        "if conll_file.exists():\n",
        "    with open(conll_file, 'r', encoding='utf-8') as f:\n",
        "        lines = f.readlines()\n",
        "    \n",
        "    print(f\"üìÑ File: {conll_file}\")\n",
        "    print(f\"üìä Total lines: {len(lines)}\")\n",
        "    \n",
        "    print(f\"\\nüìù First 50 lines:\")\n",
        "    print(\"=\" * 50)\n",
        "    for i, line in enumerate(lines[:50]):\n",
        "        print(f\"{i+1:2d}: {line.rstrip()}\")\n",
        "    \n",
        "    print(f\"\\n...\" + \".\" * 40)\n",
        "    print(f\"üìÑ Full file contains {len(lines)} lines\")\n",
        "    \n",
        "    # Count entity examples\n",
        "    entity_lines = [line for line in lines if '\\t' in line and not line.startswith('#')]\n",
        "    total_tokens = len(entity_lines)\n",
        "    entity_tokens = len([line for line in entity_lines if not line.strip().endswith('\\tO')])\n",
        "    \n",
        "    print(f\"\\nüìä Token Statistics:\")\n",
        "    print(f\"   Total tokens: {total_tokens}\")\n",
        "    print(f\"   Entity tokens: {entity_tokens}\")\n",
        "    print(f\"   Entity coverage: {(entity_tokens/total_tokens)*100:.1f}%\")\n",
        "else:\n",
        "    print(f\"‚ùå CoNLL file not found: {conll_file}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ‚úÖ Task 2 Summary\n",
        "\n",
        "### üéØ Completed Requirements\n",
        "- ‚úÖ **50 messages labeled** (requirement: 30-50)\n",
        "- ‚úÖ **CoNLL format validated** (proper BIO tagging)\n",
        "- ‚úÖ **All entity types found** (PRODUCT, LOC, PRICE)\n",
        "- ‚úÖ **Plain text file created** for NER training\n",
        "\n",
        "### üìä Final Statistics\n",
        "- **Total tokens**: 515\n",
        "- **Entity tokens**: 243 (47.2% coverage)\n",
        "- **Entity distribution**:\n",
        "  - PRODUCT: 47 entities\n",
        "  - PRICE: 100 entities \n",
        "  - LOC: 40 entities\n",
        "\n",
        "### üìÅ Output Files\n",
        "- `data/conll_labeled/amharic_ecommerce_conll.txt` - CoNLL format data\n",
        "- `data/conll_labeled/labeling_statistics.json` - Statistics\n",
        "- `data/conll_labeled/validation_report.json` - Validation report\n",
        "\n",
        "### üîÑ Next Steps (Task 3)\n",
        "Ready for **NER model fine-tuning** with:\n",
        "- Train/validation/test splits\n",
        "- Model selection (XLM-Roberta, mBERT)\n",
        "- Performance evaluation\n",
        "- Model interpretability (SHAP/LIME)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
